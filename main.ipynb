{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation\n",
    "\n",
    "This notebook includes the model training and evaluation for DeepLabv3 with ResNet101 and MobileNetV3 backbone layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "from utils import (\n",
    "    get_device, train_test_split, batch_data, files_to_tensors,\n",
    "    pixel_accuracy, iou_score, dice_score, f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset\n",
    "\n",
    "Data we use consist of POEM images and a corresponding 2D tensor comprising of the each pixel's label. The images are imported from a local directory and the tensors are store in a pickled dictionary containing the image file name as keys and tensors as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = \"/Users/naman/Workspace/Data/BM5020-POEM/Snapshots\"\n",
    "pkl_path = f\"{im_dir}/annotations.pkl\"\n",
    "# pkl_path = \"segmented_images.pkl\"\n",
    "\n",
    "classes = [\"Background\", \"Muscle layer\", \"Mucosal layer\", \"Electrode\"]\n",
    "\n",
    "with open(pkl_path, \"rb\") as file:\n",
    "    data_dict = pickle.load(file)\n",
    "\n",
    "print(\n",
    "    f\"Size of data: {len(data_dict)}\\n\"\n",
    "    f\"Classes in data: {classes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = list(data_dict.keys())\n",
    "\n",
    "train_ratio = 0.8\n",
    "shuffle = True\n",
    "train_files, test_files = train_test_split(all_files, train_ratio, shuffle)\n",
    "\n",
    "print(\n",
    "    f\"Train size: {len(train_files)}\\n\"\n",
    "    f\"Test size: {len(test_files)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "batched_train = batch_data(train_files, batch_size)\n",
    "\n",
    "print(f\"Number of batches: {len(batched_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the models\n",
    "\n",
    "We load the models with classifier head as DeepLabv3 with 2 different backbones: Resnet101 and MobileNetV3. The classifier head in our model is used to classify each pixel and the backbone layer is used for feature extraction. Backbone layers are initialised with pretrained weights whereas the classifier head is initialised with random weights and 4 number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(classes)\n",
    "\n",
    "deeplabv3_weights = models.segmentation.DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1\n",
    "resnet101_weights = models.ResNet101_Weights.IMAGENET1K_V2\n",
    "mobilenetv3_weights = models.mobilenet.MobileNet_V3_Large_Weights.IMAGENET1K_V2\n",
    "\n",
    "deeplabv3_resnet101 = models.segmentation.deeplabv3.deeplabv3_resnet101(\n",
    "    num_classes=num_classes, weights_backbone=resnet101_weights\n",
    ").to(device)\n",
    "deeplabv3_mobilenetv3 = models.segmentation.deeplabv3.deeplabv3_mobilenet_v3_large(\n",
    "    num_classes=num_classes, weights_backbone=mobilenetv3_weights\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabv3_resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabv3_mobilenetv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model to train\n",
    "model = deeplabv3_mobilenetv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the optimizer and scheduler\n",
    "\n",
    "We use the Adam optimizer with exponential scheduling. $\\gamma$ in our scheduler is the factor multiplied after each step of the scheduler (which is taken after every epoch). Hence, the learning rate at $i\\text{th}$ epoch will be $\\text{initial\\_lr} * \\gamma^i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "gamma = 0.8\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "batches = len(batched_train)\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "iou_list = [[] for _ in range(num_classes)]\n",
    "dice_list = [[] for _ in range(num_classes)]\n",
    "f1_list = [[] for _ in range(num_classes)]\n",
    "lr_vals = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    epoch_iou_list = [0] * num_classes\n",
    "    epoch_dice_list = [0] * num_classes\n",
    "    epoch_f1_list = [0] * num_classes\n",
    "\n",
    "    for batch in batched_train:\n",
    "\n",
    "        inputs, labels = files_to_tensors(batch, im_dir, data_dict)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(inputs)[\"out\"]\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions = logits.argmax(dim=1).cpu()\n",
    "        labels = labels.cpu()\n",
    "        epoch_accuracy += pixel_accuracy(predictions, labels)\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            epoch_iou_list[i] += iou_score(predictions == i, labels == i)\n",
    "            epoch_dice_list[i] += dice_score(predictions == i, labels == i)\n",
    "            epoch_f1_list[i] += f1_score(predictions == i, labels == i)\n",
    "\n",
    "    lr_val = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
    "    lr_vals.append(lr_val)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} average loss: {epoch_loss / batches}\")\n",
    "\n",
    "    loss_list.append(epoch_loss / batches)\n",
    "    accuracy_list.append(epoch_accuracy / batches)\n",
    "    for i in range(num_classes):\n",
    "        iou_list[i].append(epoch_iou_list[i] / batches)\n",
    "        dice_list[i].append(epoch_dice_list[i] / batches)\n",
    "        f1_list[i].append(epoch_f1_list[i] / batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning rate schedule\n",
    "plt.plot(lr_vals)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Learning rate schedule\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pixel accuracy\n",
    "plt.plot(accuracy_list)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Training Pixel accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IoU scores\n",
    "for i, class_ in enumerate(classes):\n",
    "    plt.plot(iou_list[i], label=f\"Class {class_}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(f\"Training IoU score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Dice scores\n",
    "for i, class_ in enumerate(classes):\n",
    "    plt.plot(dice_list[i], label=f\"Class {class_}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(f\"Training Dice score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot F1 scores\n",
    "for i, class_ in enumerate(classes):\n",
    "    plt.plot(f1_list[i], label=f\"Class {class_}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(f\"Training F1 score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs, test_labels = files_to_tensors(test_files, im_dir, data_dict)\n",
    "test_inputs = test_inputs.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(test_inputs)[\"out\"]\n",
    "\n",
    "test_labels = test_labels.cpu()\n",
    "predictions = logits.argmax(dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Test loss: {F.cross_entropy(logits, test_labels.to(device))}\\n\"\n",
    "    f\"Pixel accuracy on test set: {pixel_accuracy(predictions, test_labels)}\\n\"\n",
    ")\n",
    "for i, class_ in enumerate(classes):\n",
    "    print(\n",
    "        f\"Class {class_} IoU score: {iou_score(predictions == i, test_labels == i)}\\n\"\n",
    "        f\"Class {class_} Dice score: {dice_score(predictions == i, test_labels == i)}\\n\"\n",
    "        f\"Class {class_} F1 score: {f1_score(predictions == i, test_labels == i)}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
