{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI in Biomedicine and Healthcare [BM5020]\n",
    "# Project : Vessel and tissue recognition during third-space Endoscopy using a deep learning algorithm\n",
    "## Team Members\n",
    "- **Pradeep Mundlik, ai21btech11022@iith.ac.in**\n",
    "- **Naman Chhibbar, ma21btech110xx@iith.ac.in**\n",
    "\n",
    "#### Link to Github Repository: [Github](https://github.com/NamanChhibbar/BM5020-Project)\n",
    "#### Link to Paper PPT: [Slides](https://docs.google.com/presentation/d/1uuP4rpO48ZUkxz7x2UBRvn2n522-tvPUc-YlY8JwQa8/edit?usp=sharing)\n",
    "\n",
    "\n",
    "***This notebook contains the main code for the project. It includes the implementation of various algorithms and functions related to the project along with output to help with our analysis.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dog.jpg', <http.client.HTTPMessage at 0x792ab277fa00>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing resnest model from timm library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "class Resnest(nn.Module):\n",
    "    def __init__(self, model_name='resnest101e', pretrained=True):\n",
    "        super(Resnest, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        # self.model.fc = nn.Linear(n_features, 10)\n",
    "        self.model.fc = nn.Identity(n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "# define the preprocessing function\n",
    "def preprocess(image):\n",
    "    image = image.convert('RGB')\n",
    "    image = np.array(image)\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    image /= 255.0\n",
    "    normalise = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    image = normalise(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01111571 0.01799265 0.03249104 ... 0.01077665 0.08971523 1.6484196 ]\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = Resnest()\n",
    "# print(model)\n",
    "model.eval()\n",
    "\n",
    "# load image\n",
    "image = Image.open('dog.jpg')\n",
    "image = preprocess(image)\n",
    "\n",
    "# predict\n",
    "with torch.no_grad():\n",
    "    pred = model(image)\n",
    "    # pred = torch.sigmoid(pred)\n",
    "    pred = pred.numpy()\n",
    "\n",
    "pred = np.squeeze(pred)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchsummary in /home/pradeep/.local/lib/python3.10/site-packages (1.5.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchviz in /home/pradeep/.local/lib/python3.10/site-packages (0.0.2)\n",
      "Requirement already satisfied: graphviz in /home/pradeep/.local/lib/python3.10/site-packages (from torchviz) (0.20.1)\n",
      "Requirement already satisfied: torch in /home/pradeep/.local/lib/python3.10/site-packages (from torchviz) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/pradeep/.local/lib/python3.10/site-packages (from torch->torchviz) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/pradeep/.local/lib/python3.10/site-packages (from torch->torchviz) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/pradeep/.local/lib/python3.10/site-packages (from torch->torchviz) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/pradeep/.local/lib/python3.10/site-packages (from torch->torchviz) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/pradeep/.local/lib/python3.10/site-packages (from torch->torchviz) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in /home/pradeep/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchviz) (67.7.2)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchviz) (0.37.1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_SimpleSegmentationModel.__init__() missing 2 required positional arguments: 'backbone' and 'classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [66], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# define the model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegmentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepLabV3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary(model, input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: _SimpleSegmentationModel.__init__() missing 2 required positional arguments: 'backbone' and 'classifier'"
     ]
    }
   ],
   "source": [
    "# import deep lab v3 model\n",
    "\n",
    "!pip3 install torchsummary\n",
    "!pip3 install torchviz\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "# define the model\n",
    "model = models.segmentation.DeepLabV3()\n",
    "print(model)\n",
    "print(summary(model, input_size=(3, 224, 224)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
